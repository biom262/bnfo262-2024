{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41e9b8c9-9f87-4648-8238-b564606943a5",
   "metadata": {},
   "source": [
    "### Variant calling module\n",
    "\n",
    "**CMM262, Winter 2024**\n",
    "\n",
    "Kyle Gaulton, kgaulton@health.ucsd.edu\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6f6171-8d72-401c-9d2d-e7873a3d6c85",
   "metadata": {},
   "source": [
    "<b>In this walkthrough we will be functionally annotating variant calls from 23andme</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789a81e1-cda8-420a-a690-02c554695719",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b><u>Download and format 23andme file</u></b>\n",
    "<br><br>\n",
    "For the purposes of this walkthrough, the Harvard Personal Genome Project has publicly available genetic data from many individuals:   \n",
    "https://my.pgp-hms.org/public_genetic_data  \n",
    "<br><br>\n",
    "We will download 23andme genetic data from one of the individuals in this database\n",
    "<br><br>\n",
    "If you have used 23andme you could download your genotype data directly and annotate your own variants instead \n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449fae7a-3209-44bf-a2b4-8d2d8ae27800",
   "metadata": {},
   "outputs": [],
   "source": [
    "wget --mirror --no-parent --no-host --cut-dirs=1 https://3996cdadd6946ea4d2685f2a71949d6e-107.collections.ac2it.arvadosapi.com/_/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37371285-8577-47e4-8136-8df045332a87",
   "metadata": {},
   "source": [
    "<br>\n",
    "If we look at the file we can see that it isn't in a standard (e.g. VCF) format, but just lists the variants and the genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425325e3-3525-4119-81e5-3032343efafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "head -n 50 genome_Patrick_Finney_v4_Full_20170327075235\\[1\\].txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838b9b1c-82ce-4e8b-abb8-d55b3f3c20fc",
   "metadata": {},
   "source": [
    "<br>\n",
    "Therefore, before annotating the variant calls we need to first convert the 23andme output to a VCF\n",
    "<br><br>\n",
    "We will use a Perl script '23andme2vcf.pl' to convert the file to VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c9fdbd-27c5-4f4f-980a-bf6045dbd83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp ~/public/variantcalling/resources/23andme_v3_hg19_ref.txt.gz .\n",
    "perl ~/public/variantcalling/resources/23andme2vcf.pl genome_Patrick_Finney_v4_Full_20170327075235\\[1\\].txt my_vars.vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8521197a-01db-434c-8881-c2cb2861faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "head -n 50 my_vars.vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413920f5-38af-43a9-80ce-15c86996501b",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b><u>Functionally annotate 23andme VCF</u></b>\n",
    "<br><br>\n",
    "Next we will functionally annotate variants in the VCF file for effects on protein-coding genes and to identify variants in ClinVar using ANNOVAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6a296d-ef1c-4d77-9eae-eb200e537f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp ~/public/variantcalling/resources/annovar.tar.gz .\n",
    "gunzip annovar.tar.gz\n",
    "tar -xvf annovar.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d1f1c8-1747-414a-b141-63739512416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "perl annovar/table_annovar.pl my_vars.vcf annovar/humandb/ -buildver hg19 -out annotated -remove -protocol refGene,clinvar_20131105 -operation g,f -nastring . -vcfinput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1b121e-a66c-483f-866e-7647ea6b5242",
   "metadata": {},
   "source": [
    "<br>\n",
    "This step should produce both a VCF with the annotations included as well as a text file of variant annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1957e49-7613-4519-99f2-18c93c3dc31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -la *multianno*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9a5885-5f1e-4097-a7c1-de4f42730756",
   "metadata": {},
   "source": [
    "<br>\n",
    "If we look at the annotated text file we can see many columns - including some redundant information - so first we want to clean up the file so it is a bit easier to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b636a4f5-3de1-47a4-a7ca-f3225f684696",
   "metadata": {},
   "outputs": [],
   "source": [
    "head -n 100 annotated.hg19_multianno.vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6a80de-07e2-46cc-b713-f1b5167720e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "head -n 20 annotated.hg19_multianno.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c18113-a073-4f75-bb6f-725b1bb49b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut -f1,2,4,5,7,9,10,11,17,24 annotated.hg19_multianno.txt > annotated.hg19_multianno.trim.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada4c0f7-09f4-43cb-8b86-47bed10a1e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "head -n 20 annotated.hg19_multianno.trim.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb60bfb-0bdf-4a8b-ab38-adcf91a2f3c1",
   "metadata": {},
   "source": [
    "<br>\n",
    "Now looking at the file it is clear that genotypes for all of the variants are provided, including ones which were homozygote for the reference allele.  Therefore we need to filter the file to just those variants which are heterozygote or homozygote non-reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9d5766-56ea-4e63-9f00-129cd239097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grep -v '0/0' annotated.hg19_multianno.trim.txt > annotated.hg19_multianno.trim.nohomref.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637b6984-a7e5-4e39-a4db-6ca8e3dbad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "head -n 20 annotated.hg19_multianno.trim.nohomref.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e03622-a36b-4939-83fb-fb605ec7c3fe",
   "metadata": {},
   "source": [
    "<br>\n",
    "Finally, we want to extract variants that may have clinical significance in ClinVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5550e9-adde-4e8e-a548-cd85c5ace7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grep '[=|]pathogenic' annotated.hg19_multianno.trim.nohomref.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493b35e1-c64c-4c70-8df9-e17475465709",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b><u>Format VCF for genotype imputation using TOPMed</u></b>\n",
    "<br><br>\n",
    "Most of the variants in your genome aren't captured by the microarray used by 23andMe/Ancestry etc.  However, you can use imputation to accurately ypredict the genotypes of most (not all) variants in your genome\n",
    "<br><br>\n",
    "In order to do this, we need to take several steps to format the VCF so that it can be uploaded to an imputation server "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a35a8a-93d9-4a32-8d24-6e76ae5b552f",
   "metadata": {},
   "source": [
    "First we need to strip out the 'chr' from the chromosome column in the VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4866027-2f75-460f-ad28-e893b6f743c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "awk '{gsub(/\\chr/, \"\")}1' my_vars.vcf > my_vars.no_chr.vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14fec4d-f148-4c11-b641-278a43921106",
   "metadata": {},
   "source": [
    "Next we need to compress and index the resulting VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "750e644b-4bf2-476a-a2c3-5065f49522ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "/opt/conda/envs/variant_calling/bin/bgzip my_vars.no_chr.vcf\n",
    "/opt/conda/envs/variant_calling/bin/tabix my_vars.no_chr.vcf.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa5bfa3-94c0-4d19-8873-5522e6c1502f",
   "metadata": {},
   "source": [
    "Finally, we need to split the VCF by chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2f0fedf-8692-47a4-8869-229ebcbcda03",
   "metadata": {},
   "outputs": [],
   "source": [
    "/opt/conda/envs/variant_calling/bin/bcftools index -s my_vars.no_chr.vcf.gz | cut -f 1 | while read C; do /opt/conda/envs/variant_calling/bin/bcftools view -O z -o split.${C}.vcf.gz my_vars.no_chr.vcf.gz \"${C}\" ; done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0db03f-4b3e-49df-8f3a-5195da65e354",
   "metadata": {},
   "source": [
    "These per-chromosome VCFs can then be uploaded to TOPMed or another imputation server (will show you how this works now)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
